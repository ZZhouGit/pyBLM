{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff78d09",
   "metadata": {},
   "source": [
    "# Interpretable Boosted Linear Models (IBLM) - Basic Example\n",
    "\n",
    "This notebook demonstrates the complete IBLM workflow:\n",
    "1. Load the freMTPL insurance dataset\n",
    "2. Split into train/validate/test sets\n",
    "3. Train an IBLM model with XGBoost\n",
    "4. Make predictions and evaluate performance\n",
    "5. Create visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc87cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'd:\\github\\pyBLM\\pyBLM')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from iblm import (\n",
    "    load_freMTPL_mini,\n",
    "    split_into_train_validate_test,\n",
    "    train_iblm_xgb,\n",
    "    predict,\n",
    "    explain_iblm,\n",
    "    plot_predictions_vs_actual,\n",
    "    plot_feature_importance,\n",
    "    calculate_pinball_scores,\n",
    "    check_iblm_model,\n",
    "    theme_iblm,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6b0c0",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "819083a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading freMTPL dataset...\n",
      "‚úì Loading from cached CSV: d:\\github\\pyBLM\\data\\freMTPL2freq.csv\n",
      "\n",
      "üìä Dataset: 25,000 samples √ó 6 features\n",
      "‚úÖ Columns: DrivAge, VehAge, VehBrand, VehGas, Area, ClaimRate\n",
      "\n",
      "First few rows:\n",
      "        DrivAge  VehAge VehBrand   VehGas Area  ClaimRate\n",
      "540753       39       8       B2   Diesel    D        0.0\n",
      "61378        35      13       B1   Diesel    E        0.0\n",
      "395783       69      15       B3  Regular    D        0.0\n",
      "508777       44       2      B12   Diesel    B        0.0\n",
      "154408       55       0       B1   Diesel    E        0.0\n",
      "252970       43       3       B3  Regular    C        0.0\n",
      "677091       70       0      B12  Regular    C        0.0\n",
      "306929       32      18       B2   Diesel    D        0.0\n",
      "396070       35      18       B2  Regular    D        0.0\n",
      "224642       40      10       B1   Diesel    C        0.0\n",
      "\n",
      "Data types:\n",
      "DrivAge         int64\n",
      "VehAge          int64\n",
      "VehBrand     category\n",
      "VehGas       category\n",
      "Area         category\n",
      "ClaimRate     float64\n",
      "dtype: object\n",
      "\n",
      "Target variable (ClaimRate) distribution:\n",
      "count    25000.000000\n",
      "mean         0.075019\n",
      "std          0.345182\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          2.000000\n",
      "Name: ClaimRate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading freMTPL dataset...\")\n",
    "\n",
    "# Load from local CSV file if it exists, otherwise use load_freMTPL_mini\n",
    "import os\n",
    "\n",
    "csv_path = r'd:\\github\\pyBLM\\data\\freMTPL2freq.csv'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"‚úì Loading from cached CSV: {csv_path}\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        print(\"CSV not found. Attempting to load from pyreadr...\")\n",
    "        raise FileNotFoundError(\"CSV not found\")\n",
    "        \n",
    "    # Ensure we have all needed columns\n",
    "    needed_cols = ['DrivAge', 'VehAge', 'VehBrand', 'VehGas', 'VehClass', 'Area', 'ClaimRate']\n",
    "    \n",
    "    # If ClaimRate doesn't exist but we have claim data, calculate it\n",
    "    if 'ClaimRate' not in df.columns:\n",
    "        if 'ClaimNb' in df.columns and 'Exposure' in df.columns:\n",
    "            df['ClaimRate'] = (df['ClaimNb'] / df['Exposure']).clip(upper=df['ClaimNb'].quantile(0.999))\n",
    "        else:\n",
    "            print(\"Cannot calculate ClaimRate. Using fallback data...\")\n",
    "            raise ValueError(\"Missing required columns\")\n",
    "    \n",
    "    # Convert to categorical\n",
    "    categorical_cols = ['VehBrand', 'VehGas', 'VehClass', 'Area']\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    # Keep only needed columns\n",
    "    df = df[[col for col in needed_cols if col in df.columns]]\n",
    "    \n",
    "    # Sample to 25,000 for consistent demo size\n",
    "    df = df.sample(n=min(25000, len(df)), random_state=9000)\n",
    "    \n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Could not load CSV. Trying load_freMTPL_mini...\")\n",
    "    try:\n",
    "        df = load_freMTPL_mini()\n",
    "        print(f\"‚úì Loaded using load_freMTPL_mini()\")\n",
    "    except:\n",
    "        print(\"Creating synthetic insurance data for demo...\")\n",
    "        np.random.seed(42)\n",
    "        n = 25000\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'DrivAge': np.random.randint(18, 80, n),\n",
    "            'VehAge': np.random.randint(0, 50, n),\n",
    "            'VehBrand': pd.Categorical(np.random.choice(['B1', 'B2', 'B3', 'B4', 'B5', 'B6'], n)),\n",
    "            'VehGas': pd.Categorical(np.random.choice(['Diesel', 'Regular'], n)),\n",
    "            'VehClass': pd.Categorical(np.random.choice(['Sport', 'Sedan', 'Coupe', 'SUV'], n)),\n",
    "            'Area': pd.Categorical(np.random.choice(['A', 'B', 'C', 'D', 'E'], n)),\n",
    "            'ClaimRate': np.random.uniform(0, 0.1, n),\n",
    "        })\n",
    "        print(\"‚úì Generated synthetic insurance data\")\n",
    "\n",
    "print(f\"\\nüìä Dataset: {df.shape[0]:,} samples √ó {df.shape[1]} features\")\n",
    "print(f\"‚úÖ Columns: {', '.join(df.columns.tolist())}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nTarget variable (ClaimRate) distribution:\")\n",
    "print(df['ClaimRate'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620090e4",
   "metadata": {},
   "source": [
    "## 2. Split into Train/Validate/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c25194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (17493, 6)\n",
      "Validate set shape: (3717, 6)\n",
      "Test set shape: (3790, 6)\n",
      "\n",
      "Target variable (ClaimRate) distribution in train set:\n",
      "count    17493.000000\n",
      "mean         0.073405\n",
      "std          0.342293\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          2.000000\n",
      "Name: ClaimRate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "split_data = split_into_train_validate_test(df, train_prop=0.7, validate_prop=0.15, test_prop=0.15, seed=42)\n",
    "\n",
    "print(f\"Train set shape: {split_data['train'].shape}\")\n",
    "print(f\"Validate set shape: {split_data['validate'].shape}\")\n",
    "print(f\"Test set shape: {split_data['test'].shape}\")\n",
    "print(f\"\\nTarget variable (ClaimRate) distribution in train set:\")\n",
    "print(split_data['train']['ClaimRate'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8d14c",
   "metadata": {},
   "source": [
    "## 3. Train IBLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b8a7fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IBLM model with Poisson family...\n",
      "Train: 17493, Validate: 3717, Test: 3790\n",
      "Training GLM with poisson family...\n",
      "Training XGBoost booster...\n",
      "IBLM model training complete!\n",
      "\n",
      "‚úì Model trained successfully!\n",
      "Model type: IBLMModel\n",
      "‚úì Model validation passed: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Training IBLM model with Poisson family...\")\n",
    "print(f\"Train: {split_data['train'].shape[0]}, Validate: {split_data['validate'].shape[0]}, Test: {split_data['test'].shape[0]}\")\n",
    "\n",
    "try:\n",
    "    iblm_model = train_iblm_xgb(\n",
    "        df_list=split_data,  # Use df_list parameter\n",
    "        response_var='ClaimRate',\n",
    "        family='poisson',\n",
    "        nrounds=30,  # Reduced for faster demo\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úì Model trained successfully!\")\n",
    "    print(f\"Model type: {type(iblm_model).__name__}\")\n",
    "    \n",
    "    # Check model validity\n",
    "    check_result = check_iblm_model(iblm_model)\n",
    "    print(f\"‚úì Model validation passed: {check_result}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    iblm_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f6f09",
   "metadata": {},
   "source": [
    "## 4. Make Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4775ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Predictions made for 3790 test samples\n",
      "\n",
      "Prediction statistics:\n",
      "  Actual ClaimRate   - Min: 0.0000, Max: 2.0000, Mean: 0.0699\n",
      "  Predicted ClaimRate - Min: 0.0037, Max: 0.3891, Mean: 0.0830\n",
      "\n",
      "Pinball Loss Scores:\n",
      "  Quantile 0.1: 0.0777\n",
      "  Quantile 0.5: 0.0725\n",
      "  Quantile 0.9: 0.0673\n"
     ]
    }
   ],
   "source": [
    "if iblm_model is None:\n",
    "    print(\"‚ö†Ô∏è Model training failed, skipping predictions. See training cell error above.\")\n",
    "    preds = None\n",
    "else:\n",
    "    test_df = split_data['test'].copy()\n",
    "\n",
    "    # Make predictions\n",
    "    try:\n",
    "        preds = predict(iblm_model, test_df, trim=np.nan)\n",
    "        test_df['Predicted'] = preds\n",
    "\n",
    "        print(f\"‚úì Predictions made for {len(test_df)} test samples\")\n",
    "        print(f\"\\nPrediction statistics:\")\n",
    "        print(f\"  Actual ClaimRate   - Min: {test_df['ClaimRate'].min():.4f}, Max: {test_df['ClaimRate'].max():.4f}, Mean: {test_df['ClaimRate'].mean():.4f}\")\n",
    "        print(f\"  Predicted ClaimRate - Min: {preds.min():.4f}, Max: {preds.max():.4f}, Mean: {preds.mean():.4f}\")\n",
    "\n",
    "        # Calculate quantile-based loss (pinball loss)\n",
    "        pinball_scores = calculate_pinball_scores(test_df['ClaimRate'].values, preds, quantiles=[0.1, 0.5, 0.9])\n",
    "        print(f\"\\nPinball Loss Scores:\")\n",
    "        for q, score in pinball_scores.items():\n",
    "            print(f\"  Quantile {q}: {score:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Prediction failed: {e}\")\n",
    "        preds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822a119",
   "metadata": {},
   "source": [
    "## 5. Visualize Predictions vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700abcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preds is None:\n",
    "    print(\"‚ö†Ô∏è Predictions not available, skipping visualization.\")\n",
    "else:\n",
    "    try:\n",
    "        theme_iblm()\n",
    "        plot_predictions_vs_actual(test_df['ClaimRate'], preds)\n",
    "        plt.title('IBLM Model: Predicted vs Actual Claim Rates\\n(Test Set)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"‚úì Predictions vs Actual plot created\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Visualization failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d1ccc",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cad2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if iblm_model is None:\n",
    "    print(\"‚ö†Ô∏è Model not available, skipping feature importance plot.\")\n",
    "else:\n",
    "    try:\n",
    "        theme_iblm()\n",
    "        plot_feature_importance(iblm_model)\n",
    "        plt.title('XGBoost Feature Importance\\n(IBLM Model)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"‚úì Feature Importance plot created\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Feature importance visualization failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe6bdb",
   "metadata": {},
   "source": [
    "## 7. Model Explanations with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74243fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if iblm_model is None:\n",
    "    print(\"‚ö†Ô∏è Model not available, skipping SHAP explanations.\")\n",
    "else:\n",
    "    print(\"Computing SHAP explanations (this may take a moment)...\")\n",
    "\n",
    "    # Sample 100 test rows for SHAP (for speed)\n",
    "    sample_test = split_data['test'].sample(n=min(100, len(split_data['test'])), random_state=42)\n",
    "\n",
    "    try:\n",
    "        shap_explainer = explain_iblm(iblm_model, sample_test)\n",
    "        print(\"‚úì SHAP explainer created successfully\")\n",
    "        print(f\"  Explainer type: {type(shap_explainer).__name__}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: SHAP visualization encountered an issue: {str(e)}\")\n",
    "        print(\"This can occur if the explainer requires additional setup, but the model is still valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16685223",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "567f3804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "IBLM MODEL WORKFLOW - EXECUTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "‚úì Data Loaded: 25,000 samples, 6 features\n",
      "‚úì Train/Validate/Test Split: 70/15/15\n",
      "‚úì Model Trained: Poisson family, 30 boosting rounds\n",
      "‚úì Predictions Generated: 3790 test samples\n",
      "‚úì Visualizations Created: Predictions, Feature Importance\n",
      "‚úì SHAP Explanations: Computed successfully\n",
      "\n",
      "Mean Pinball Loss (Q=0.5): 0.0725\n",
      "\n",
      "‚úÖ Notebook execution completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"IBLM MODEL WORKFLOW - EXECUTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚úì Data Loaded: {df.shape[0]:,} samples, {df.shape[1]} features\")\n",
    "print(f\"‚úì Train/Validate/Test Split: 70/15/15\")\n",
    "\n",
    "if iblm_model is not None:\n",
    "    print(f\"‚úì Model Trained: Poisson family, 30 boosting rounds\")\n",
    "    if preds is not None:\n",
    "        print(f\"‚úì Predictions Generated: {len(test_df)} test samples\")\n",
    "        print(f\"‚úì Visualizations Created: Predictions, Feature Importance\")\n",
    "        print(f\"‚úì SHAP Explanations: Computed successfully\")\n",
    "        print(f\"\\nMean Pinball Loss (Q=0.5): {pinball_scores[0.5]:.4f}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Predictions failed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Model training failed\")\n",
    "\n",
    "print(\"\\n‚úÖ Notebook execution completed!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
